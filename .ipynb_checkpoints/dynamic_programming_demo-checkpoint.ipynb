{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming for Reinforcement Learning with Gridworld Examples\n",
    "\n",
    "\n",
    "### Topics\n",
    "\n",
    "* Policy Iteration\n",
    "* Value Iteration\n",
    "* Asynchronous Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are my own\n",
    "from grid_world_env_deterministic import grid_world_env_deterministic as deterministic_enviro\n",
    "from grid_renderer import grid_renderer\n",
    "\n",
    "import turtle\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.set_printoptions(suppress=True, threshold=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 4. 0.]\n",
      " [4. 0. 0. 0. 0.]\n",
      " [0. 4. 0. 0. 4.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 4. 3.]]\n"
     ]
    }
   ],
   "source": [
    "height = 5\n",
    "width = 5\n",
    "hole_id = 4\n",
    "goal_id = 3\n",
    "blank_id = 0\n",
    "agent_id = 1\n",
    "num_of_acts = 4\n",
    "terminal_state = 5\n",
    "evn_state = 0\n",
    "agent_state = 1\n",
    "hole_penalty = -10\n",
    "step_penalty = -1\n",
    "\n",
    "env = deterministic_enviro()\n",
    "state, _, _, _ = env.reset()\n",
    "state = state[0:int(len(state)/2)]\n",
    "state = np.reshape(state, (height, width))\n",
    "goal_locations = state == goal_id\n",
    "hole_locations = state == hole_id\n",
    "print(state)\n",
    "renderer = grid_renderer(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the environment looks like. The black represent holes, and the red represents the goal\n",
    "![image of environment](./images/blank_environment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can probe the environment to obtain the following matrix, which gives the rewards for choosing an action from each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -1.  -1. -10.  -1.]\n",
      "  [ -1.  -1.  -1.  -1.]\n",
      "  [ -1. -10.  -1.  -1.]\n",
      "  [-10.  -1.  -1.  -1.]\n",
      "  [ -1.  -1.  -1. -10.]]\n",
      "\n",
      " [[ -1.  -1.  -1. -10.]\n",
      "  [ -1.  -1. -10. -10.]\n",
      "  [ -1.  -1.  -1.  -1.]\n",
      "  [-10.  -1.  -1.  -1.]\n",
      "  [ -1.  -1. -10.  -1.]]\n",
      "\n",
      " [[-10. -10.  -1.  -1.]\n",
      "  [ -1.  -1.  -1.  -1.]\n",
      "  [ -1.  -1.  -1. -10.]\n",
      "  [ -1. -10.  -1.  -1.]\n",
      "  [ -1. -10.  -1.  -1.]]\n",
      "\n",
      " [[ -1.  -1.  -1.  -1.]\n",
      "  [-10.  -1.  -1.  -1.]\n",
      "  [ -1.  -1.  -1.  -1.]\n",
      "  [ -1.  -1. -10.  -1.]\n",
      "  [-10.  -1.   0.  -1.]]\n",
      "\n",
      " [[ -1.  -1.  -1.  -1.]\n",
      "  [ -1.  -1.  -1.  -1.]\n",
      "  [ -1. -10.  -1.  -1.]\n",
      "  [ -1.   0. -10.  -1.]\n",
      "  [ -1.   0.   0. -10.]]]\n"
     ]
    }
   ],
   "source": [
    "rewards = np.zeros((height, width, num_of_acts))\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        for action in range(num_of_acts):\n",
    "            _, rewards[y][x][action], _, _ = env.hypothetical((x,y), action)\n",
    "\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following defines the state that will follow each state given an action. This environment is deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for start_row in range(height):\n",
    "    actions.append([])\n",
    "    for start_col in range(width):\n",
    "        actions[start_row].append([])\n",
    "        for action in range(num_of_acts):\n",
    "            row = start_row\n",
    "            col = start_col\n",
    "            if action == 0 and row > 0:\n",
    "                row -= 1\n",
    "            elif action == 1 and col < width - 1:\n",
    "                col += 1\n",
    "            elif action == 2 and row < height - 1:\n",
    "                row += 1\n",
    "            elif action == 3 and col > 0:\n",
    "                col -= 1\n",
    "            actions[start_row][start_col].append((row, col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters I will use to start with. Gamma is the discount factor, and theta is how close to no change in values the algorithm will go before it considers policy evaluation complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "theta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Policy iteration algorithm](./images/policy_iteration_formula_page_80.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to run turtle visualizer\n",
    "#renderer.grid_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a visual representation of the optimal policy determined through policy iteration\n",
    "![optimal policy visualized](./images/optimal_policy_visual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma_height = 3\n",
    "# gamma_width = 3\n",
    "# gamma_env = deterministic_enviro(height=gamma_height, width=gamma_width, hole_quantity=0)\n",
    "# gamma_state, _, _, _ = env.reset()\n",
    "# gamma_state = gamma_state[0:int(len(gamma_state)/2)]\n",
    "# gamma_state = np.reshape(gamma_state, (gamma_height, gamma_width))\n",
    "# goal_locations = gamma_state == goal_id\n",
    "# hole_locations = gamma_state == hole_id\n",
    "# print(gamma_state)\n",
    "# renderer = grid_renderer(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This evaluates the policy 66 times. Let's try something more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visual representation of policy iteration](./images/policy_iteration_visual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visual representation of value iteration](./images/value_iteration_visual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![value iteration algorithm](./images/value_iteration_formula_page_83.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an implementation of synchronous value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "step  1\n",
      "[[-10.  -1.  -1. -10.  -1.]\n",
      " [-10. -10.  -1.  -1.  -1.]\n",
      " [ -1. -10.  -1.  -1. -10.]\n",
      " [ -1.  -1.  -1.  -1.   0.]\n",
      " [ -1.  -1.  -1. -10.   0.]]\n",
      "1.0\n",
      "step  2\n",
      "[[-11.  -2.  -2. -10.  -2.]\n",
      " [-10. -11.  -2.  -2.  -2.]\n",
      " [ -2. -10.  -2.  -2. -10.]\n",
      " [ -2.  -2.  -2.  -2.   0.]\n",
      " [ -2.  -2.  -2. -10.   0.]]\n",
      "1.0\n",
      "step  3\n",
      "[[-11.  -3.  -3. -10.  -3.]\n",
      " [-10. -11.  -3.  -3.  -3.]\n",
      " [ -3. -10.  -3.  -3. -10.]\n",
      " [ -3.  -3.  -3.  -3.   0.]\n",
      " [ -3.  -3.  -3. -10.   0.]]\n",
      "1.0\n",
      "step  4\n",
      "[[-11.  -4.  -4. -10.  -4.]\n",
      " [-10. -11.  -4.  -4.  -4.]\n",
      " [ -4. -10.  -4.  -4. -10.]\n",
      " [ -4.  -4.  -4.  -4.   0.]\n",
      " [ -4.  -4.  -4. -10.   0.]]\n",
      "1.0\n",
      "step  5\n",
      "[[-11.  -5.  -5. -10.  -5.]\n",
      " [-10. -11.  -5.  -5.  -5.]\n",
      " [ -5. -10.  -5.  -5. -10.]\n",
      " [ -5.  -5.  -5.  -5.   0.]\n",
      " [ -5.  -5.  -5. -10.   0.]]\n",
      "1.0\n",
      "step  6\n",
      "[[-11.  -6.  -6. -10.  -6.]\n",
      " [-10. -11.  -6.  -6.  -6.]\n",
      " [ -6. -10.  -6.  -6. -10.]\n",
      " [ -6.  -6.  -6.  -6.   0.]\n",
      " [ -6.  -6.  -6. -10.   0.]]\n",
      "1.0\n",
      "step  7\n",
      "[[-11.  -7.  -7. -10.  -7.]\n",
      " [-10. -11.  -7.  -7.  -7.]\n",
      " [ -7. -10.  -7.  -7. -10.]\n",
      " [ -7.  -7.  -7.  -7.   0.]\n",
      " [ -7.  -7.  -7. -10.   0.]]\n",
      "1.0\n",
      "step  8\n",
      "[[-11.  -8.  -8. -10.  -8.]\n",
      " [-10. -11.  -8.  -8.  -8.]\n",
      " [ -8. -10.  -8.  -8. -10.]\n",
      " [ -8.  -8.  -8.  -8.   0.]\n",
      " [ -8.  -8.  -8. -10.   0.]]\n",
      "1.0\n",
      "step  9\n",
      "[[-11.  -9.  -9. -10.  -9.]\n",
      " [-10. -11.  -9.  -9.  -9.]\n",
      " [ -9. -10.  -9.  -9. -10.]\n",
      " [ -9.  -9.  -9.  -9.   0.]\n",
      " [ -9.  -9.  -9. -10.   0.]]\n",
      "1.0\n",
      "step  10\n",
      "[[-11. -10. -10. -10. -10.]\n",
      " [-10. -11. -10. -10. -10.]\n",
      " [-10. -10. -10. -10. -10.]\n",
      " [-10. -10. -10. -10.   0.]\n",
      " [-10. -10. -10. -10.   0.]]\n",
      "1.0\n",
      "step  11\n",
      "[[-11. -11. -11. -10. -11.]\n",
      " [-10. -11. -11. -11. -11.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n",
      "1.0\n",
      "step  12\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -12. -11. -12.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n",
      "0.0\n",
      "step  13\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -12. -11. -12.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n"
     ]
    }
   ],
   "source": [
    "delta = 1.0\n",
    "\n",
    "#Values are intialized arbitrarily \n",
    "values = np.zeros((height, width))\n",
    "values[hole_locations] = hole_penalty\n",
    "old_values = np.array(values)\n",
    "\n",
    "synchronous_step = 1\n",
    "while delta > theta:\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            if not (goal_locations[row][col] or hole_locations[row][col]):\n",
    "                next_state_vals = []\n",
    "                for action in range(num_of_acts):\n",
    "                    next_spot = actions[row][col][action]\n",
    "                    if not (next_spot[0] == col and next_spot[1] == row):\n",
    "                        next_val = rewards[row][col][action] + (gamma * old_values[next_spot[1]][next_spot[0]])\n",
    "                        next_state_vals.append(next_val)\n",
    "                if len(next_state_vals) != 0:\n",
    "                    values[row][col] = max(next_state_vals)\n",
    "                    \n",
    "    delta = np.amax(abs(np.subtract(old_values, values)))\n",
    "    print(delta)\n",
    "    print('step ', synchronous_step)\n",
    "    synchronous_step += 1\n",
    "    \n",
    "    old_values = np.array(values)\n",
    "    values = np.zeros((height, width))\n",
    "    values[hole_locations] = hole_penalty\n",
    "\n",
    "    print(old_values)\n",
    "    \n",
    "values = old_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like success, but let's check the policy. The code below gives a greedy policy correlating to the values calculated above. For this policy, and all of my gridworld environments, 0 is up, 1 is right, 2 is down, and 3 is left. The 5's below represent terminal states. Here is a graphical interpretation of it from my gridworld renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 3. 2.]\n",
      " [2. 0. 0. 1. 1.]\n",
      " [3. 3. 1. 2. 2.]\n",
      " [0. 1. 1. 1. 5.]]\n"
     ]
    }
   ],
   "source": [
    "#TODO: put this in a separate file\n",
    "\n",
    "new_policy = np.zeros((height, width))\n",
    "\n",
    "index = 0\n",
    "for row in range(height):\n",
    "    for col in range(width):\n",
    "        if not goal_locations[row][col]:\n",
    "            max_next_state_val = -100000 #this should never naturally occur\n",
    "            for action in range(num_of_acts):\n",
    "                if (actions[row][col][action][0] != col or actions[row][col][action][1] != row):\n",
    "                    next_spot = actions[row][col][action]\n",
    "                    next_state_val = values[next_spot[1]][next_spot[0]]\n",
    "                    if next_state_val > max_next_state_val:\n",
    "                        max_next_state_val = next_state_val\n",
    "                        new_policy[row][col] = action\n",
    "        else:\n",
    "            new_policy[row][col] = terminal_state\n",
    "\n",
    "        index += 1\n",
    "        \n",
    "print(new_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches the optimal policy previously obtained from policy iteration. Policy iteration and value iteration both went through 8 policy improvements. However, under value iteration, there were only 8 policy evaluations under value iteration compared with 66 policy evaluations under policy iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asychronous Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far, I've been using synchronous value iteration. I want to see if asynchronous value iteration can do the job in fewer iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "step  1\n",
      "[[-10.  -1.  -1. -10.  -1.]\n",
      " [-10. -10.  -1.  -1.  -1.]\n",
      " [ -1. -10.  -1.  -1. -10.]\n",
      " [ -1.  -1.  -1.  -1.   0.]\n",
      " [ -1.  -1.  -1. -10.   0.]]\n",
      "1.0\n",
      "step  2\n",
      "[[-11.  -2.  -2. -10.  -2.]\n",
      " [-10. -11.  -2.  -2.  -2.]\n",
      " [ -2. -10.  -2.  -2. -10.]\n",
      " [ -2.  -2.  -2.  -2.   0.]\n",
      " [ -2.  -2.  -2. -10.   0.]]\n",
      "1.0\n",
      "step  3\n",
      "[[-11.  -3.  -3. -10.  -3.]\n",
      " [-10. -11.  -3.  -3.  -3.]\n",
      " [ -3. -10.  -3.  -3. -10.]\n",
      " [ -3.  -3.  -3.  -3.   0.]\n",
      " [ -3.  -3.  -3. -10.   0.]]\n",
      "1.0\n",
      "step  4\n",
      "[[-11.  -4.  -4. -10.  -4.]\n",
      " [-10. -11.  -4.  -4.  -4.]\n",
      " [ -4. -10.  -4.  -4. -10.]\n",
      " [ -4.  -4.  -4.  -4.   0.]\n",
      " [ -4.  -4.  -4. -10.   0.]]\n",
      "1.0\n",
      "step  5\n",
      "[[-11.  -5.  -5. -10.  -5.]\n",
      " [-10. -11.  -5.  -5.  -5.]\n",
      " [ -5. -10.  -5.  -5. -10.]\n",
      " [ -5.  -5.  -5.  -5.   0.]\n",
      " [ -5.  -5.  -5. -10.   0.]]\n",
      "1.0\n",
      "step  6\n",
      "[[-11.  -6.  -6. -10.  -6.]\n",
      " [-10. -11.  -6.  -6.  -6.]\n",
      " [ -6. -10.  -6.  -6. -10.]\n",
      " [ -6.  -6.  -6.  -6.   0.]\n",
      " [ -6.  -6.  -6. -10.   0.]]\n",
      "1.0\n",
      "step  7\n",
      "[[-11.  -7.  -7. -10.  -7.]\n",
      " [-10. -11.  -7.  -7.  -7.]\n",
      " [ -7. -10.  -7.  -7. -10.]\n",
      " [ -7.  -7.  -7.  -7.   0.]\n",
      " [ -7.  -7.  -7. -10.   0.]]\n",
      "1.0\n",
      "step  8\n",
      "[[-11.  -8.  -8. -10.  -8.]\n",
      " [-10. -11.  -8.  -8.  -8.]\n",
      " [ -8. -10.  -8.  -8. -10.]\n",
      " [ -8.  -8.  -8.  -8.   0.]\n",
      " [ -8.  -8.  -8. -10.   0.]]\n",
      "1.0\n",
      "step  9\n",
      "[[-11.  -9.  -9. -10.  -9.]\n",
      " [-10. -11.  -9.  -9.  -9.]\n",
      " [ -9. -10.  -9.  -9. -10.]\n",
      " [ -9.  -9.  -9.  -9.   0.]\n",
      " [ -9.  -9.  -9. -10.   0.]]\n",
      "1.0\n",
      "step  10\n",
      "[[-11. -10. -10. -10. -10.]\n",
      " [-10. -11. -10. -10. -10.]\n",
      " [-10. -10. -10. -10. -10.]\n",
      " [-10. -10. -10. -10.   0.]\n",
      " [-10. -10. -10. -10.   0.]]\n",
      "1.0\n",
      "step  11\n",
      "[[-11. -11. -11. -10. -11.]\n",
      " [-10. -11. -11. -11. -11.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n",
      "1.0\n",
      "step  12\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -12. -11. -12.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n",
      "0.0\n",
      "step  13\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -12. -11. -12.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n"
     ]
    }
   ],
   "source": [
    "delta = 1.0\n",
    "\n",
    "#Values are intialized arbitrarily \n",
    "values = np.zeros((height, width))\n",
    "values[hole_locations] = hole_penalty\n",
    "old_values = np.array(values)\n",
    "\n",
    "asynchronous_step = 1\n",
    "while delta > theta:\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            if not (goal_locations[row][col] or hole_locations[row][col]):\n",
    "                next_state_vals = []\n",
    "                for action in range(num_of_acts):\n",
    "                    next_spot = actions[row][col][action]\n",
    "                    if not (next_spot[0] == col and next_spot[1] == row):\n",
    "                        next_val = rewards[row][col][action] + (gamma * old_values[next_spot[1]][next_spot[0]])\n",
    "                        next_state_vals.append(next_val)\n",
    "                if len(next_state_vals) != 0:\n",
    "                    values[row][col] = max(next_state_vals)\n",
    "    \n",
    "    delta = np.amax(abs(np.subtract(old_values, values)))\n",
    "    print(delta)\n",
    "    print('step ', asynchronous_step)\n",
    "    asynchronous_step += 1\n",
    "    \n",
    "    old_values = np.copy(values)\n",
    "\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final values for synchronous and asynchronous have come out the same, and it took the same amount of steps. This took me by surprise for a second until I considered the order values are calculated in, left to right and top to bottom, thus visiting the goal last. I'm going to reverse the order and see if there is a difference, which I do expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "step  1\n",
      "[[-11.  -1.  -2. -10.  -2.]\n",
      " [-10. -10.  -1.  -2.  -2.]\n",
      " [ -1. -10.  -2.  -1. -10.]\n",
      " [ -1.  -1.  -1.  -1.   0.]\n",
      " [ -1.  -1.  -1. -10.   0.]]\n",
      "3.0\n",
      "step  2\n",
      "[[-11.  -4.  -4. -10.  -4.]\n",
      " [-10. -11.  -3.  -4.  -3.]\n",
      " [ -3. -10.  -4.  -3. -10.]\n",
      " [ -3.  -2.  -3.  -2.   0.]\n",
      " [ -3.  -3.  -2. -10.   0.]]\n",
      "2.0\n",
      "step  3\n",
      "[[-11.  -6.  -6. -10.  -5.]\n",
      " [-10. -11.  -5.  -5.  -5.]\n",
      " [ -5. -10.  -6.  -5. -10.]\n",
      " [ -5.  -4.  -5.  -4.   0.]\n",
      " [ -4.  -4.  -4. -10.   0.]]\n",
      "2.0\n",
      "step  4\n",
      "[[-11.  -8.  -8. -10.  -7.]\n",
      " [-10. -11.  -7.  -7.  -7.]\n",
      " [ -7. -10.  -7.  -7. -10.]\n",
      " [ -6.  -6.  -6.  -6.   0.]\n",
      " [ -6.  -6.  -6. -10.   0.]]\n",
      "2.0\n",
      "step  5\n",
      "[[-11. -10. -10. -10.  -9.]\n",
      " [-10. -11.  -9.  -9.  -9.]\n",
      " [ -9. -10.  -9.  -8. -10.]\n",
      " [ -8.  -8.  -8.  -7.   0.]\n",
      " [ -8.  -8.  -8. -10.   0.]]\n",
      "2.0\n",
      "step  6\n",
      "[[-11. -11. -11. -10. -11.]\n",
      " [-10. -11. -10. -11. -10.]\n",
      " [-11. -10. -11. -10. -10.]\n",
      " [-10.  -9. -10.  -9.   0.]\n",
      " [-10. -10.  -9. -10.   0.]]\n",
      "2.0\n",
      "step  7\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -12. -11. -12.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n",
      "0.0\n",
      "step  8\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -12. -11. -12.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n"
     ]
    }
   ],
   "source": [
    "delta = 1.0\n",
    "\n",
    "#Values are intialized arbitrarily \n",
    "values = np.zeros((height, width))\n",
    "values[hole_locations] = hole_penalty\n",
    "old_values = np.array(values)\n",
    "\n",
    "asynchronous_step = 1\n",
    "while delta > theta:\n",
    "    for row in range(height-1, -1, -1):\n",
    "        for col in range(width-1, -1, -1):\n",
    "            if not (goal_locations[row][col] or hole_locations[row][col]):\n",
    "                next_state_vals = []\n",
    "                for action in range(num_of_acts):\n",
    "                    next_spot = actions[row][col][action]\n",
    "                    if not (next_spot[0] == col and next_spot[1] == row):\n",
    "                        next_val = rewards[row][col][action] + (gamma * values[next_spot[1]][next_spot[0]])\n",
    "                        next_state_vals.append(next_val)\n",
    "                if len(next_state_vals) != 0:\n",
    "                    values[row][col] = max(next_state_vals)\n",
    "    \n",
    "    delta = np.amax(abs(np.subtract(old_values, values)))\n",
    "    print(delta)\n",
    "    print('step ', asynchronous_step)\n",
    "    asynchronous_step += 1\n",
    "    \n",
    "    old_values = np.copy(values)\n",
    "\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There it is. Asynchronous value iteration has achieved the same thing as synchronous value iteration in almost half the amount of steps, 5 compared to 8. However, it required being clever about how to implement the scanning. Out of curiosity, I will now implement asynchronous value iteration with pseudo-random ordering but being sure to visit every space once before moving to the next step. I expect this to be somewhere between the last two exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "step  1\n",
      "[[-10.  -1.  -1. -10.  -1.]\n",
      " [-10. -10.  -1.  -2.  -1.]\n",
      " [ -2. -10.  -2.  -1. -10.]\n",
      " [ -1.  -2.  -1.  -2.   0.]\n",
      " [ -1.  -1.  -2. -10.   0.]]\n",
      "2.0\n",
      "step  2\n",
      "[[-11.  -3.  -3. -10.  -2.]\n",
      " [-10. -11.  -3.  -2.  -2.]\n",
      " [ -2. -10.  -2.  -3. -10.]\n",
      " [ -2.  -3.  -3.  -2.   0.]\n",
      " [ -3.  -3.  -3. -10.   0.]]\n",
      "2.0\n",
      "step  3\n",
      "[[-11.  -5.  -5. -10.  -4.]\n",
      " [-10. -11.  -5.  -4.  -4.]\n",
      " [ -4. -10.  -4.  -5. -10.]\n",
      " [ -4.  -4.  -3.  -4.   0.]\n",
      " [ -5.  -5.  -4. -10.   0.]]\n",
      "2.0\n",
      "step  4\n",
      "[[-11.  -5.  -5. -10.  -6.]\n",
      " [-10. -11.  -5.  -6.  -5.]\n",
      " [ -6. -10.  -6.  -5. -10.]\n",
      " [ -5.  -6.  -5.  -6.   0.]\n",
      " [ -6.  -5.  -5. -10.   0.]]\n",
      "2.0\n",
      "step  5\n",
      "[[-11.  -7.  -7. -10.  -6.]\n",
      " [-10. -11.  -7.  -6.  -6.]\n",
      " [ -6. -10.  -6.  -7. -10.]\n",
      " [ -6.  -6.  -7.  -6.   0.]\n",
      " [ -7.  -7.  -6. -10.   0.]]\n",
      "2.0\n",
      "step  6\n",
      "[[-11.  -9.  -7. -10.  -8.]\n",
      " [-10. -11.  -7.  -8.  -8.]\n",
      " [ -8. -10.  -8.  -7. -10.]\n",
      " [ -8.  -7.  -7.  -8.   0.]\n",
      " [ -9.  -7.  -7. -10.   0.]]\n",
      "2.0\n",
      "step  7\n",
      "[[-11.  -9.  -9. -10. -10.]\n",
      " [-10. -11.  -9.  -8.  -8.]\n",
      " [-10. -10.  -8.  -8. -10.]\n",
      " [ -9.  -9.  -9.  -8.   0.]\n",
      " [ -9.  -9.  -8. -10.   0.]]\n",
      "2.0\n",
      "step  8\n",
      "[[-11. -11. -11. -10. -10.]\n",
      " [-10. -11.  -9. -10. -10.]\n",
      " [-11. -10. -10.  -9. -10.]\n",
      " [-11. -10.  -9. -10.   0.]\n",
      " [-11.  -9. -10. -10.   0.]]\n",
      "2.0\n",
      "step  9\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -11. -10. -10.]\n",
      " [-11. -10. -10. -11. -10.]\n",
      " [-11. -10. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n",
      "2.0\n",
      "step  10\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -12. -11. -12.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n",
      "0.0\n",
      "step  11\n",
      "[[-11. -11. -11. -10. -12.]\n",
      " [-10. -11. -12. -11. -12.]\n",
      " [-11. -10. -11. -11. -10.]\n",
      " [-11. -11. -11. -10.   0.]\n",
      " [-11. -11. -10. -10.   0.]]\n"
     ]
    }
   ],
   "source": [
    "delta = 1.0\n",
    "\n",
    "#Values are intialized arbitrarily \n",
    "values = np.zeros((height, width))\n",
    "values[hole_locations] = hole_penalty\n",
    "old_values = np.copy(values)\n",
    "\n",
    "asynchronous_step = 1\n",
    "\n",
    "states = [(x,y) for x in range(width) for y in range(height) if not goal_locations[y][x]]\n",
    "random.shuffle(states)\n",
    "\n",
    "while delta > theta:\n",
    "    for state in states:\n",
    "        col, row = state\n",
    "        if not (goal_locations[row][col] or hole_locations[row][col]):\n",
    "            next_state_vals = []\n",
    "            for action in range(num_of_acts):\n",
    "                next_spot = actions[row][col][action]\n",
    "                if not (next_spot[0] == col and next_spot[1] == row):\n",
    "                    next_val = rewards[row][col][action] + (gamma * values[next_spot[1]][next_spot[0]])\n",
    "                    next_state_vals.append(next_val)\n",
    "            if len(next_state_vals) != 0:\n",
    "                values[row][col] = max(next_state_vals)\n",
    "    \n",
    "    delta = np.amax(abs(np.subtract(old_values, values)))\n",
    "    print(delta)\n",
    "    print('step ', asynchronous_step)\n",
    "    asynchronous_step += 1\n",
    "    \n",
    "    old_values = np.copy(values)\n",
    "    \n",
    "    random.shuffle(states)\n",
    "\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above block several times, I can confirm that random state selection takes between 6 and 8 steps. It makes sense that the previous two examples serve as upper and power bounds for efficiency. As such, one would expect randomness to fall in the middle. This might be worth keeping in mind for less intuitive optimal policies in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Notes and Things I've Learned\n",
    "\n",
    "Interesting things to note:\n",
    "\n",
    "I tried making holes terminal states, so the agent's optimal policy was to jump in the nearest hole to end discounting returns.\n",
    "\n",
    "When there are no rewards available and no maximum steps, penalize each step taken or add a small penalty to being in each state, except the final state. Because value iteration takes the maximum next value, and the value of the terminal state is 0 by definition, problems will arise. It will attempt to discount 0, which is zero, and state values of 0 will propagate out from the final states with each iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 0. 5. 4. 5.]\n",
      " [4. 5. 0. 5. 5.]\n",
      " [5. 4. 5. 5. 4.]\n",
      " [0. 5. 0. 5. 5.]\n",
      " [0. 0. 5. 4. 3.]]\n"
     ]
    }
   ],
   "source": [
    "from grid_world_env_stochastic import grid_world_env_stochastic as stochastic_enviro\n",
    "env = stochastic_enviro()\n",
    "state, _, _, _ = env.reset()\n",
    "state = state[0:int(len(state)/2)]\n",
    "state = np.reshape(state, (height, width))\n",
    "goal_locations = state == goal_id\n",
    "hole_locations = state == hole_id\n",
    "print(state)\n",
    "renderer = grid_renderer(state)\n",
    "#renderer.colored_spots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.zeros((num_of_acts, len(state) * len(state[0]), len(state) * len(state[0])))\n",
    "i = 0\n",
    "for row in range(len(state)):\n",
    "    for col in range(len(state[0])):\n",
    "        for action in range(num_of_acts):\n",
    "            next_row, next_col = actions[row][col][action]\n",
    "            if state[next_row][next_col] in (0, 3, 4):\n",
    "                index = row * len(state[0]) + col \n",
    "                transition_matrix[action][i][index] = 1.\n",
    "            elif state[next_row][next_col] == 5:\n",
    "                remainder = 1.\n",
    "                for act in range(num_of_acts):\n",
    "                    n_row, n_col = actions[next_row][next_col][act]\n",
    "                    if state[n_row][n_col] == 4:\n",
    "                        index = n_row * len(state[0]) + n_col \n",
    "                        transition_matrix[action][i][index] += 0.25\n",
    "                        remainder -= 0.25\n",
    "                index = next_row * len(state[0]) + next_col\n",
    "                transition_matrix[action][i][index] = remainder\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.75 0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.75 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.25 0.75 0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.75 0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.75 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.25 0.75 0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.25 0.5  0.   0.   0.   0.   0.25 0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.   0.   0.   0.\n",
      "   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.5  0.25 0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.75 0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75\n",
      "   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.\n",
      "   0.   0.   0.75 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.25 0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.  ]]\n",
      "\n",
      " [[1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.75 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.25 0.75 0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.25 0.75 0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.25 0.5  0.   0.   0.   0.   0.25 0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.   0.   0.   0.\n",
      "   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.   0.   0.   0.\n",
      "   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.75 0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75\n",
      "   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.\n",
      "   0.   0.   0.75 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.25 0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.25 0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "\n",
      " [[1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.25 0.5  0.   0.   0.   0.   0.25 0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.   0.   0.   0.\n",
      "   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.5  0.25 0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.75 0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75\n",
      "   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.\n",
      "   0.   0.   0.75 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.25 0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.25 0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.25 0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "\n",
      " [[0.75 0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.75 0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.75 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.25 0.5  0.   0.   0.   0.   0.25 0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.5  0.25 0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.5  0.25 0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.75 0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75\n",
      "   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.\n",
      "   0.   0.   0.75 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.25 0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.25 0.  ]\n",
      "  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]]\n"
     ]
    }
   ],
   "source": [
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.zeros((len(state) * len(state[0]), len(state) * len(state[0])))\n",
    "i = 0\n",
    "for row in range(len(state)):\n",
    "    for col in range(len(state[0])):\n",
    "        if state[row][col] in (0, 3, 4):\n",
    "            index = row * len(state[0]) + col \n",
    "            transition_matrix[i][index] = 1.\n",
    "        elif state[row][col] == 5:\n",
    "            remainder = 1.\n",
    "            for act in range(num_of_acts):\n",
    "                n_row, n_col = actions[row][col][act]\n",
    "                if state[n_row][n_col] == 4:\n",
    "                    index = n_row * len(state[0]) + n_col \n",
    "                    transition_matrix[i][index] += 0.25\n",
    "                    remainder -= 0.25\n",
    "            index = row * len(state[0]) + col\n",
    "            transition_matrix[i][index] = remainder\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75 0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.75 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.25 0.75 0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.25 0.5  0.   0.   0.   0.   0.25 0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.   0.   0.   0.\n",
      "  0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.5  0.25 0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.75 0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.75\n",
      "  0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.\n",
      "  0.   0.   0.75 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.25 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.25 0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.75 0.25 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochasctic Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.25\n",
      "step  1\n",
      "[[ -1.9   -1.    -1.   -10.    -3.25]\n",
      " [-10.    -1.    -1.    -1.    -3.25]\n",
      " [ -1.9  -10.    -1.    -3.25 -10.  ]\n",
      " [ -1.    -1.    -1.    -1.     0.  ]\n",
      " [ -1.    -1.    -1.   -10.     0.  ]]\n",
      "2.1937499999999996\n",
      "step  2\n",
      "[[ -2.71     -1.9      -1.9     -10.       -5.44375]\n",
      " [-10.       -1.9      -1.9      -1.9      -5.44375]\n",
      " [ -2.71    -10.       -1.9      -3.925   -10.     ]\n",
      " [ -1.9      -1.9      -1.9      -1.9       0.     ]\n",
      " [ -1.9      -1.9      -1.9     -10.        0.     ]]\n",
      "1.4807812500000006\n",
      "step  3\n",
      "[[ -3.439       -2.71        -2.71       -10.          -6.92453125]\n",
      " [-10.          -2.71        -2.71        -2.71        -6.92453125]\n",
      " [ -3.439      -10.          -2.71        -4.5325     -10.        ]\n",
      " [ -2.71        -2.71        -2.71        -2.71         0.        ]\n",
      " [ -2.71        -2.71        -2.71       -10.           0.        ]]\n",
      "0.9995273437499996\n",
      "step  4\n",
      "[[ -4.0951      -3.439       -3.439      -10.          -7.92405859]\n",
      " [-10.          -3.439       -3.439       -3.439       -7.92405859]\n",
      " [ -4.0951     -10.          -3.439       -5.07925    -10.        ]\n",
      " [ -3.439       -3.439       -3.439       -3.439        0.        ]\n",
      " [ -3.439       -3.439       -3.439      -10.           0.        ]]\n",
      "0.6746809570312502\n",
      "step  5\n",
      "[[ -4.68559     -4.0951      -4.0951     -10.          -8.59873955]\n",
      " [-10.          -4.0951      -4.0951      -4.0951      -8.59873955]\n",
      " [ -4.68559    -10.          -4.0951      -5.571325   -10.        ]\n",
      " [ -4.0951      -4.0951      -4.0951      -4.0951       0.        ]\n",
      " [ -4.0951      -4.0951      -4.0951     -10.           0.        ]]\n",
      "0.59049\n",
      "step  6\n",
      "[[ -5.217031   -4.68559    -4.68559   -10.         -9.0541492]\n",
      " [-10.         -4.68559    -4.68559    -4.68559    -9.0541492]\n",
      " [ -5.217031  -10.         -4.68559    -6.0141925 -10.       ]\n",
      " [ -4.68559    -4.68559    -4.68559    -4.68559     0.       ]\n",
      " [ -4.68559    -4.68559    -4.68559   -10.          0.       ]]\n",
      "0.531441\n",
      "step  7\n",
      "[[ -5.6953279   -5.217031    -5.217031   -10.          -9.36155071]\n",
      " [-10.          -5.217031    -5.217031    -5.217031    -9.36155071]\n",
      " [ -5.6953279  -10.          -5.217031    -6.41277325 -10.        ]\n",
      " [ -5.217031    -5.217031    -5.217031    -5.217031     0.        ]\n",
      " [ -5.217031    -5.217031    -5.217031   -10.           0.        ]]\n",
      "0.47829690000000014\n",
      "step  8\n",
      "[[ -6.12579511  -5.6953279   -5.6953279  -10.          -9.56904673]\n",
      " [-10.          -5.6953279   -5.6953279   -5.6953279   -9.56904673]\n",
      " [ -6.12579511 -10.          -5.6953279   -6.77149592 -10.        ]\n",
      " [ -5.6953279   -5.6953279   -5.6953279   -5.6953279    0.        ]\n",
      " [ -5.6953279   -5.6953279   -5.6953279  -10.           0.        ]]\n",
      "0.43046720999999977\n",
      "step  9\n",
      "[[ -6.5132156   -6.12579511  -6.12579511 -10.          -9.70910654]\n",
      " [-10.          -6.12579511  -6.12579511  -6.12579511  -9.70910654]\n",
      " [ -6.5132156  -10.          -6.12579511  -7.09434633 -10.        ]\n",
      " [ -6.12579511  -6.12579511  -6.12579511  -6.12579511   0.        ]\n",
      " [ -6.12579511  -6.12579511  -6.12579511 -10.           0.        ]]\n",
      "0.38742048900000015\n",
      "step  10\n",
      "[[ -6.86189404  -6.5132156   -6.5132156  -10.          -9.80364692]\n",
      " [-10.          -6.5132156   -6.5132156   -6.5132156   -9.80364692]\n",
      " [ -6.86189404 -10.          -6.5132156   -7.3849117  -10.        ]\n",
      " [ -6.5132156   -6.5132156   -6.5132156   -6.5132156    0.        ]\n",
      " [ -6.5132156   -6.5132156   -6.5132156  -10.           0.        ]]\n",
      "0.3486784401000005\n",
      "step  11\n",
      "[[ -7.17570464  -6.86189404  -6.86189404 -10.          -9.86746167]\n",
      " [-10.          -6.86189404  -6.86189404  -6.86189404  -9.86746167]\n",
      " [ -7.17570464 -10.          -6.86189404  -7.64642053 -10.        ]\n",
      " [ -6.86189404  -6.86189404  -6.86189404  -6.86189404   0.        ]\n",
      " [ -6.86189404  -6.86189404  -6.86189404 -10.           0.        ]]\n",
      "0.3138105960899997\n",
      "step  12\n",
      "[[ -7.45813417  -7.17570464  -7.17570464 -10.          -9.91053663]\n",
      " [-10.          -7.17570464  -7.17570464  -7.17570464  -9.91053663]\n",
      " [ -7.45813417 -10.          -7.17570464  -7.88177848 -10.        ]\n",
      " [ -7.17570464  -7.17570464  -7.17570464  -7.17570464   0.        ]\n",
      " [ -7.17570464  -7.17570464  -7.17570464 -10.           0.        ]]\n",
      "0.28242953648099967\n",
      "step  13\n",
      "[[ -7.71232075  -7.45813417  -7.45813417 -10.          -9.93961222]\n",
      " [-10.          -7.45813417  -7.45813417  -7.45813417  -9.93961222]\n",
      " [ -7.71232075 -10.          -7.45813417  -8.09360063 -10.        ]\n",
      " [ -7.45813417  -7.45813417  -7.45813417  -7.45813417   0.        ]\n",
      " [ -7.45813417  -7.45813417  -7.45813417 -10.           0.        ]]\n",
      "0.25418658283289997\n",
      "step  14\n",
      "[[ -7.94108868  -7.71232075  -7.71232075 -10.          -9.95923825]\n",
      " [-10.          -7.71232075  -7.71232075  -7.71232075  -9.95923825]\n",
      " [ -7.94108868 -10.          -7.71232075  -8.28424057 -10.        ]\n",
      " [ -7.71232075  -7.71232075  -7.71232075  -7.71232075   0.        ]\n",
      " [ -7.71232075  -7.71232075  -7.71232075 -10.           0.        ]]\n",
      "0.2287679245496097\n",
      "step  15\n",
      "[[ -8.14697981  -7.94108868  -7.94108868 -10.          -9.97248582]\n",
      " [-10.          -7.94108868  -7.94108868  -7.94108868  -9.97248582]\n",
      " [ -8.14697981 -10.          -7.94108868  -8.45581651 -10.        ]\n",
      " [ -7.94108868  -7.94108868  -7.94108868  -7.94108868   0.        ]\n",
      " [ -7.94108868  -7.94108868  -7.94108868 -10.           0.        ]]\n",
      "0.20589113209465015\n",
      "step  16\n",
      "[[ -8.33228183  -8.14697981  -8.14697981 -10.          -9.98142793]\n",
      " [-10.          -8.14697981  -8.14697981  -8.14697981  -9.98142793]\n",
      " [ -8.33228183 -10.          -8.14697981  -8.61023486 -10.        ]\n",
      " [ -8.14697981  -8.14697981  -8.14697981  -8.14697981   0.        ]\n",
      " [ -8.14697981  -8.14697981  -8.14697981 -10.           0.        ]]\n",
      "0.18530201888518505\n",
      "step  17\n",
      "[[ -8.49905365  -8.33228183  -8.33228183 -10.          -9.98746385]\n",
      " [-10.          -8.33228183  -8.33228183  -8.33228183  -9.98746385]\n",
      " [ -8.49905365 -10.          -8.33228183  -8.74921137 -10.        ]\n",
      " [ -8.33228183  -8.33228183  -8.33228183  -8.33228183   0.        ]\n",
      " [ -8.33228183  -8.33228183  -8.33228183 -10.           0.        ]]\n",
      "0.16677181699666477\n",
      "step  18\n",
      "[[ -8.64914828  -8.49905365  -8.49905365 -10.          -9.9915381 ]\n",
      " [-10.          -8.49905365  -8.49905365  -8.49905365  -9.9915381 ]\n",
      " [ -8.64914828 -10.          -8.49905365  -8.87429024 -10.        ]\n",
      " [ -8.49905365  -8.49905365  -8.49905365  -8.49905365   0.        ]\n",
      " [ -8.49905365  -8.49905365  -8.49905365 -10.           0.        ]]\n",
      "0.1500946352969983\n",
      "step  19\n",
      "[[ -8.78423345  -8.64914828  -8.64914828 -10.          -9.99428822]\n",
      " [-10.          -8.64914828  -8.64914828  -8.64914828  -9.99428822]\n",
      " [ -8.78423345 -10.          -8.64914828  -8.98686121 -10.        ]\n",
      " [ -8.64914828  -8.64914828  -8.64914828  -8.64914828   0.        ]\n",
      " [ -8.64914828  -8.64914828  -8.64914828 -10.           0.        ]]\n",
      "0.13508517176729917\n",
      "step  20\n",
      "[[ -8.90581011  -8.78423345  -8.78423345 -10.          -9.99614455]\n",
      " [-10.          -8.78423345  -8.78423345  -8.78423345  -9.99614455]\n",
      " [ -8.90581011 -10.          -8.78423345  -9.08817509 -10.        ]\n",
      " [ -8.78423345  -8.78423345  -8.78423345  -8.78423345   0.        ]\n",
      " [ -8.78423345  -8.78423345  -8.78423345 -10.           0.        ]]\n",
      "0.12157665459056943\n",
      "step  21\n",
      "[[ -9.0152291   -8.90581011  -8.90581011 -10.          -9.99739757]\n",
      " [-10.          -8.90581011  -8.90581011  -8.90581011  -9.99739757]\n",
      " [ -9.0152291  -10.          -8.90581011  -9.17935758 -10.        ]\n",
      " [ -8.90581011  -8.90581011  -8.90581011  -8.90581011   0.        ]\n",
      " [ -8.90581011  -8.90581011  -8.90581011 -10.           0.        ]]\n",
      "0.10941898913151249\n",
      "step  22\n",
      "[[ -9.11370619  -9.0152291   -9.0152291  -10.          -9.99824336]\n",
      " [-10.          -9.0152291   -9.0152291   -9.0152291   -9.99824336]\n",
      " [ -9.11370619 -10.          -9.0152291   -9.26142182 -10.        ]\n",
      " [ -9.0152291   -9.0152291   -9.0152291   -9.0152291    0.        ]\n",
      " [ -9.0152291   -9.0152291   -9.0152291  -10.           0.        ]]\n",
      "0.0984770902183616\n",
      "step  23\n",
      "[[ -9.20233557  -9.11370619  -9.11370619 -10.          -9.99881427]\n",
      " [-10.          -9.11370619  -9.11370619  -9.11370619  -9.99881427]\n",
      " [ -9.20233557 -10.          -9.11370619  -9.33527964 -10.        ]\n",
      " [ -9.11370619  -9.11370619  -9.11370619  -9.11370619   0.        ]\n",
      " [ -9.11370619  -9.11370619  -9.11370619 -10.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "delta = 1.0\n",
    "gamma = 0.9\n",
    "\n",
    "rewards = np.zeros((height, width))\n",
    "rewards -= 1.\n",
    "rewards[hole_locations] = -10\n",
    "rewards[goal_locations] = 0\n",
    "\n",
    "\n",
    "#Values are intialized arbitrarily \n",
    "values = np.copy(rewards)\n",
    "old_values = np.array(values)\n",
    "\n",
    "asynchronous_step = 1\n",
    "while delta > theta:\n",
    "    for row in range(height-1, -1, -1):\n",
    "        for col in range(width-1, -1, -1):\n",
    "            if not (goal_locations[row][col] or hole_locations[row][col]):\n",
    "                next_state_vals = []\n",
    "                for action in range(num_of_acts):\n",
    "                    next_row, next_col = actions[row][col][action]\n",
    "                    if state[next_row][next_col] in (0, 3, 4):\n",
    "                        next_val = rewards[next_row][next_col] + (gamma * values[next_row][next_col])\n",
    "                        next_state_vals.append(next_val)\n",
    "                    else:\n",
    "                        index = (next_row * len(state[0])) + col\n",
    "                        next_val = 0\n",
    "                        for s in range(len(state) * len(state[0])):\n",
    "                            if transition_matrix[index][s] > 0:\n",
    "                                r = s // len(state[0])\n",
    "                                c = s % len(state[0])\n",
    "                                next_val += transition_matrix[index][s] * (rewards[next_row][next_col] + gamma * values[r][c])\n",
    "                        next_state_vals.append(next_val)\n",
    "                if len(next_state_vals) != 0:\n",
    "                    values[row][col] = max(next_state_vals)\n",
    "    \n",
    "    delta = np.amax(abs(np.subtract(old_values, values)))\n",
    "    print(delta)\n",
    "    print('step ', asynchronous_step)\n",
    "    asynchronous_step += 1\n",
    "    \n",
    "    old_values = np.copy(values)\n",
    "\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
